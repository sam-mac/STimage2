{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e64a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from anndata import read_h5ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "# Add the src/ directory as one where we can import modules\n",
    "src_dir = \"../src\"\n",
    "sys.path.append(src_dir)\n",
    "from utils import VisiumClassificationDataset\n",
    "from dkl import initial_values, GP, DKL, GP_Natural\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "# from torchvision.io import read_image\n",
    "# from torchvision.transforms import ToTensor\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "\n",
    "from gpytorch.mlls import VariationalELBO\n",
    "from gpytorch.likelihoods import SoftmaxLikelihood\n",
    "from gpytorch import settings as gpytorch_settings\n",
    "from gpytorch.optim import NGD\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5efee48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the location where models will be saved to\n",
    "if torch.hub.get_dir() == '/clusterdata/uqsmac12/.cache/torch/hub':\n",
    "    torch.hub.set_dir('/scratch/smp/uqsmac12/.cache/torch/hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fefa9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA = '/scratch/smp/uqsmac12/stimage2_data'\n",
    "\n",
    "# DIR_WANDB = DIR_DATA\n",
    "DIR_TILES = '/scratch/smp/uqsmac12/dataset_breast_cancer_9visium'\n",
    "DIR_ANNDATA_PROCESSED = '/scratch/smp/uqsmac12/dataset_breast_cancer_9visium'\n",
    "file_processed_alex_data = 'all_adata.h5ad'\n",
    "# DIR_PROCESSED_DATA = '/afm03/Q2/Q2051/STimage_project/STimage_dataset/PROCESSED/dataset_breast_cancer_9visium'\n",
    "DIR_RAW_DATA = '/afm03/Q2/Q2051/STimage_project/STimage_dataset/RAW/Alex_NatGen_6BreastCancer'\n",
    "DIR_RAW_METADATA = os.path.join(DIR_RAW_DATA, 'metadata')\n",
    "\n",
    "DIR_CHECKPOINTS = os.path.join(DIR_DATA, 'checkpoints/')\n",
    "# location to save data\n",
    "DIR_PROCESSED_DATASET = os.path.join(DIR_DATA, 'data_processed')\n",
    "FILE_PROCESSED_VISIUM9 = os.path.join(DIR_PROCESSED_DATASET, 'df_adata_rna_logcpt_images_labels_visium9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66574ae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_164673/2114264811.py:2: DtypeWarning: Columns (10,13,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_data = pd.read_csv(FILE_PROCESSED_VISIUM9, index_col='Unnamed: 0.1')\n"
     ]
    }
   ],
   "source": [
    "# load csv\n",
    "df_data = pd.read_csv(FILE_PROCESSED_VISIUM9, index_col='Unnamed: 0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2704ab68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# drop instances without cancer labels\n",
    "df_data = df_data[df_data['cancer_class'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aef8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train val and test datasets\n",
    "df_test = df_data[df_data['library'] == 'CID4465']\n",
    "df_train = df_data[df_data['library'] != 'CID4465']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51bec08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the rows preserving unique set of instances \n",
    "df_train = df_train.sample(frac=1, replace=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a636a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_train.iloc[:1000, :].copy()\n",
    "df_train = df_train.iloc[1000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d9833d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get transformations\n",
    "transform_scale = transforms.Lambda(lambda x: x / 255.)\n",
    "transform_normalise = ResNet34_Weights.DEFAULT.transforms()\n",
    "composed_transforms = transforms.Compose([transform_scale, transform_normalise])\n",
    "# preprocess = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ae636e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset objects\n",
    "dataset_train = VisiumClassificationDataset(df_train, transform=composed_transforms)\n",
    "dataset_val = VisiumClassificationDataset(df_val, transform=composed_transforms)\n",
    "dataset_test = VisiumClassificationDataset(df_test, transform=composed_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf1309ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "batch_size = 384\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=False, )\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size)\n",
    "dataloader_test = DataLoader(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6099972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load pretrained model and reset final fully connected layer\n",
    "feature_extractor = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "num_final_fc_in = feature_extractor.fc.in_features # get number of features\n",
    "# replace final layer\n",
    "num_features_out = 128\n",
    "feature_extractor.fc = nn.Linear(num_final_fc_in, num_features_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7302291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_inducing_points = 200\n",
    "initial_inducing_points, initial_lengthscale = initial_values(\n",
    "    dataset_train, feature_extractor, num_inducing_points,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e696f452",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initial_lengthscale' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMatern52\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Matern52 # RBF # Matern32\u001b[39;00m\n\u001b[1;32m      2\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      3\u001b[0m gp \u001b[38;5;241m=\u001b[39m GP_Natural(\n\u001b[1;32m      4\u001b[0m     num_outputs\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[0;32m----> 5\u001b[0m     initial_lengthscale\u001b[38;5;241m=\u001b[39m\u001b[43minitial_lengthscale\u001b[49m,\n\u001b[1;32m      6\u001b[0m     initial_inducing_points\u001b[38;5;241m=\u001b[39minitial_inducing_points,\n\u001b[1;32m      7\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initial_lengthscale' is not defined"
     ]
    }
   ],
   "source": [
    "kernel = 'Matern52' # Matern52 # RBF # Matern32\n",
    "num_classes = 2\n",
    "gp = GP(\n",
    "# gp = GP_Natural(\n",
    "    num_outputs=num_classes,\n",
    "    initial_lengthscale=initial_lengthscale,\n",
    "    initial_inducing_points=initial_inducing_points,\n",
    "    kernel=kernel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5854f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DKL(feature_extractor, gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d025d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = SoftmaxLikelihood(num_classes=num_classes, mixing_weights=False)\n",
    "likelihood = likelihood.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d9fd6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "elbo_fn = VariationalELBO(likelihood, gp, num_data=len(dataset_train))\n",
    "loss_fn = lambda x, y: -elbo_fn(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2353c9f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(\n",
    "#     model.parameters(),\n",
    "#     lr=1e-4,\n",
    "#     weight_decay=1e-2,\n",
    "# )\n",
    "variational_ngd_optimizer = NGD(\n",
    "    model.variational_parameters(), \n",
    "    num_data=len(dataset_train), \n",
    "    lr=1e-4\n",
    ")\n",
    "hyperparameter_optimizer = torch.optim.Adam([\n",
    "    {'params': model.hyperparameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cda53e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if variational_ngd_optimizer:\n",
    "    print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73a0fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(hyperparameter_optimizer, step_size=10, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b5e9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': dataloader_train, 'val': dataloader_val, 'test': dataloader_test}\n",
    "dataset_sizes = {'train': len(dataloader_train.dataset), 'val': len(dataloader_val.dataset), 'test': len(dataloader_test.dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b16c7730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dir_best_model_params=DIR_CHECKPOINTS, num_epochs=50, optimizer_variational_ngd=None):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    best_model_params_path = os.path.join(dir_best_model_params, 'best_model_params.pt')\n",
    "    torch.save(model.state_dict(), best_model_params_path)\n",
    "    best_acc = 0.0\n",
    "    model = model.cuda()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase], total=len(dataloaders[phase]) , leave = False):\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    pred_MVN = model(inputs)\n",
    "                    # Convert a â€¦ x N MVN distribution into a batch of independent Normal distributions. \n",
    "                    # Essentially, this throws away all covariance information and treats all dimensions as batch dimensions.\n",
    "                    pred_MVN = pred_MVN.to_data_independent_dist() \n",
    "                    \n",
    "                    with gpytorch_settings.num_likelihood_samples(15):\n",
    "                        # the average of samples from the likelihood; matrix dims=(batch_size, num_classes) \n",
    "                        pred_mean_prob = likelihood(pred_MVN).probs.mean(0)\n",
    "                        # predicted index/class_id come from 2nd index position from the output tupple\n",
    "                        pred_class_id = pred_mean_prob.max(dim=1)[1]\n",
    "                    # criterion is the (negative) variational elbo corresponding the the SoftMaxLikelihood\n",
    "                    loss = criterion(pred_MVN, labels)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        # get the gradients\n",
    "                        loss.backward()\n",
    "                        # optimize \n",
    "                        optimizer.step()\n",
    "                        ### ### ### ### ### ### ### ### ### ### ### ### \n",
    "                        # potential second step for NGD\n",
    "                        if optimizer_variational_ngd:\n",
    "                            variational_ngd_optimizer.zero_grad()\n",
    "                            pred_MVN = model(inputs)\n",
    "                            loss = criterion(pred_MVN, labels)\n",
    "                            loss.backward()\n",
    "                            optimizer_variational_ngd.step()\n",
    "                        ### ### ### ### ### ### ### ### ### ### ### ### \n",
    "                        \n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(pred_class_id == labels.data)\n",
    "            if phase == 'train':\n",
    "                # step the learning rate schedule\n",
    "                scheduler.step() \n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "        \n",
    "        # epoch ended share the time.\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Epoch {epoch} finished at time {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(torch.load(best_model_params_path))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4b8fbc1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2984 Acc: 0.8615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 44.0485 Acc: 0.9080\n",
      "Epoch 0 finished at time 3m 28s\n",
      "Epoch 1/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0815 Acc: 0.9659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 37.6067 Acc: 0.9280\n",
      "Epoch 1 finished at time 6m 50s\n",
      "Epoch 2/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0243 Acc: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 42.0358 Acc: 0.9290\n",
      "Epoch 2 finished at time 10m 13s\n",
      "Epoch 3/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0154 Acc: 0.9938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 43.3935 Acc: 0.9270\n",
      "Epoch 3 finished at time 13m 33s\n",
      "Epoch 4/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0131 Acc: 0.9934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 45.5707 Acc: 0.9270\n",
      "Epoch 4 finished at time 16m 52s\n",
      "Epoch 5/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0115 Acc: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 66.9438 Acc: 0.9040\n",
      "Epoch 5 finished at time 20m 11s\n",
      "Epoch 6/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0109 Acc: 0.9955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 41.5599 Acc: 0.9300\n",
      "Epoch 6 finished at time 23m 32s\n",
      "Epoch 7/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0106 Acc: 0.9974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 50.4073 Acc: 0.9240\n",
      "Epoch 7 finished at time 26m 48s\n",
      "Epoch 8/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0100 Acc: 0.9981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 44.9913 Acc: 0.9250\n",
      "Epoch 8 finished at time 30m 9s\n",
      "Epoch 9/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameter_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_variational_ngd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariational_ngd_optimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 24\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, best_model_params_path, num_epochs, optimizer_variational_ngd)\u001b[0m\n\u001b[1;32m     21\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloaders[phase], total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloaders[phase]) , leave \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     25\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     26\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/STimage2/src/utils.py:18\u001b[0m, in \u001b[0;36mVisiumClassificationDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     17\u001b[0m         idx_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_data\u001b[38;5;241m.\u001b[39mindex[idx]\n\u001b[0;32m---> 18\u001b[0m         X_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#         y = self.get_expression(idx_name)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_class(idx_name)\n",
      "File \u001b[0;32m~/STimage2/src/utils.py:29\u001b[0m, in \u001b[0;36mVisiumClassificationDataset.load_img\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     26\u001b[0m X_img \u001b[38;5;241m=\u001b[39m read_image(img_path)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 29\u001b[0m     X_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_img\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torchvision/transforms/_presets.py:56\u001b[0m, in \u001b[0;36mImageClassification.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 56\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcenter_crop(img, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrop_size)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, Tensor):\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torchvision/transforms/functional.py:476\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    473\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F_pil\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39mpil_interpolation)\n\u001b[0;32m--> 476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:469\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, antialias)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# Define align_corners to avoid warnings\u001b[39;00m\n\u001b[1;32m    467\u001b[0m align_corners \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m interpolation \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbicubic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 469\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpolation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbicubic\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m out_dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39muint8:\n\u001b[1;32m    472\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m)\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torch/nn/functional.py:3950\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m antialias:\n\u001b[1;32m   3949\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_upsample_bilinear2d_aa(\u001b[38;5;28minput\u001b[39m, output_size, align_corners, scale_factors)\n\u001b[0;32m-> 3950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsample_bilinear2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3952\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m align_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train_model(model, loss_fn, hyperparameter_optimizer, exp_lr_scheduler, optimizer_variational_ngd=variational_ngd_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3492d4cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 98.7711 Acc: 0.8239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 93.1365 Acc: 0.8090\n",
      "Epoch 0 finished at time 2m 60s\n",
      "Epoch 1/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 93.8696 Acc: 0.8480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 88.7781 Acc: 0.8140\n",
      "Epoch 1 finished at time 5m 53s\n",
      "Epoch 2/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 89.9032 Acc: 0.8710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 83.2975 Acc: 0.8660\n",
      "Epoch 2 finished at time 8m 50s\n",
      "Epoch 3/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 86.0231 Acc: 0.8877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 80.5704 Acc: 0.8780\n",
      "Epoch 3 finished at time 11m 47s\n",
      "Epoch 4/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 82.5547 Acc: 0.8974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 78.1572 Acc: 0.8830\n",
      "Epoch 4 finished at time 14m 43s\n",
      "Epoch 5/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 79.5191 Acc: 0.9076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 80.7858 Acc: 0.8570\n",
      "Epoch 5 finished at time 17m 43s\n",
      "Epoch 6/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 76.8293 Acc: 0.9192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 75.2085 Acc: 0.9020\n",
      "Epoch 6 finished at time 20m 37s\n",
      "Epoch 7/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 73.0879 Acc: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 69.6625 Acc: 0.9060\n",
      "Epoch 7 finished at time 23m 39s\n",
      "Epoch 8/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 70.3950 Acc: 0.9368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 71.1320 Acc: 0.8990\n",
      "Epoch 8 finished at time 26m 34s\n",
      "Epoch 9/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 68.2058 Acc: 0.9429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 69.3369 Acc: 0.9060\n",
      "Epoch 9 finished at time 29m 28s\n",
      "Epoch 10/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 64.2379 Acc: 0.9530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 70.7596 Acc: 0.8890\n",
      "Epoch 10 finished at time 32m 21s\n",
      "Epoch 11/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 24\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, best_model_params_path, num_epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloaders[phase], total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloaders[phase]) , leave \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     25\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     26\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/STimage2/src/utils.py:18\u001b[0m, in \u001b[0;36mVisiumClassificationDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     17\u001b[0m         idx_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_data\u001b[38;5;241m.\u001b[39mindex[idx]\n\u001b[0;32m---> 18\u001b[0m         X_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#         y = self.get_expression(idx_name)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_class(idx_name)\n",
      "File \u001b[0;32m~/STimage2/src/utils.py:26\u001b[0m, in \u001b[0;36mVisiumClassificationDataset.load_img\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"load an image\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_data\u001b[38;5;241m.\u001b[39mloc[key, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtile_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 26\u001b[0m X_img \u001b[38;5;241m=\u001b[39m \u001b[43mread_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     29\u001b[0m     X_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(X_img)\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torchvision/io/image.py:254\u001b[0m, in \u001b[0;36mread_image\u001b[0;34m(path, mode)\u001b[0m\n\u001b[1;32m    252\u001b[0m     _log_api_usage_once(read_image)\n\u001b[1;32m    253\u001b[0m data \u001b[38;5;241m=\u001b[39m read_file(path)\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torchvision/io/image.py:231\u001b[0m, in \u001b[0;36mdecode_image\u001b[0;34m(input, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[1;32m    230\u001b[0m     _log_api_usage_once(decode_image)\n\u001b[0;32m--> 231\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/scratch/smp/uqsmac12/.conda/env/lit_torch_gp/lib/python3.8/site-packages/torch/_ops.py:442\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train_model(model, loss_fn, optimizer, exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdbdf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_uncertainties(prob_tensor):\n",
    "    \"\"\"\n",
    "    Compute uncertainties from a collection of simulation probabilities.\n",
    "\n",
    "    Args:\n",
    "    - prob_tensor: Tensor of shape [num_simulations, batch_size, num_classes]\n",
    "\n",
    "    Returns:\n",
    "    - epistemic_uncertainty: Epistemic uncertainty for each item in the batch.\n",
    "    - aleatoric_uncertainty: Aleatoric uncertainty for each item in the batch.\n",
    "    - predictive_uncertainty: Total predictive uncertainty (Shannon's entropy) for each item in the batch.\n",
    "    \"\"\"\n",
    "    # Calculate mean and variance across simulations\n",
    "    mean_probs = prob_tensor.mean(dim=0)  # shape: [batch_size, num_classes]\n",
    "    var_probs = prob_tensor.var(dim=0)  # shape: [batch_size, num_classes]\n",
    "\n",
    "    # Epistemic Uncertainty: variance of the expected predictions across simulations\n",
    "    epistemic_uncertainty = var_probs  # summing over classes\n",
    "\n",
    "    # Aleatoric Uncertainty: entropy of the average prediction\n",
    "    aleatoric_uncertainty = -mean_probs * torch.log(mean_probs + 1e-10)\n",
    "\n",
    "    # Predictive Uncertainty (Shannon's entropy): averaged entropy over all simulations\n",
    "    entropies = -torch.sum(prob_tensor * torch.log(prob_tensor + 1e-10), dim=2)  # shape: [num_simulations, batch_size]\n",
    "    predictive_uncertainty = entropies.mean(dim=0)\n",
    "\n",
    "    return epistemic_uncertainty, aleatoric_uncertainty, predictive_uncertainty\n",
    "\n",
    "def evaluate_and_return_predictions(model, criterion, dataloader_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance on the test set and return a DataFrame with predictions.\n",
    "    \n",
    "    Args:\n",
    "    - model: Trained model.\n",
    "    - criterion: Loss function used during training.\n",
    "    - dataloader_test: DataLoader object for the test set.\n",
    "    \n",
    "    Returns:\n",
    "    - df: DataFrame with columns \"label\", \"pred_class_id\", and \"loss\".\n",
    "    \"\"\"\n",
    "    model = model.cuda()\n",
    "    model.eval()  # Set model to evaluate mode\n",
    "    \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_losses = []\n",
    "    \n",
    "    # Iterate over the test data\n",
    "    for inputs, labels in tqdm(dataloader_test, total=len(dataloader_test), leave=False):\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        # forward\n",
    "        with torch.no_grad():\n",
    "            pred_MVN = model(inputs)\n",
    "            pred_MVN = pred_MVN.to_data_independent_dist()\n",
    "            with gpytorch_settings.num_likelihood_samples(15):\n",
    "                prob_sims = likelihood(pred_MVN).probs\n",
    "                epistemic_unc, aleatoric_unc, predictive_unc = compute_uncertainties(prob_sims)\n",
    "                pred_mean_prob = prob_sims.mean(0)\n",
    "                pred_class_id = pred_mean_prob.max(dim=1)[1]\n",
    "                \n",
    "            loss = criterion(pred_MVN, labels)\n",
    "\n",
    "        # collect results\n",
    "        all_labels.extend(labels.cpu().numpy().tolist())\n",
    "        all_preds.extend(pred_class_id.cpu().numpy().tolist())\n",
    "        all_losses.extend([loss.item()] * inputs.size(0))\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'label': all_labels,\n",
    "        'pred_class_id': all_preds,\n",
    "        'loss': all_losses\n",
    "    })\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e00b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "# Example\n",
    "prob_tensor = torch.rand([10, 384, 2])\n",
    "prob_tensor = F.softmax(prob_tensor, dim=-1)  # Make sure the tensor represents valid probabilities\n",
    "epistemic, aleatoric, predictive = compute_uncertainties(prob_tensor)\n",
    "print(epistemic, aleatoric, predictive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2e94392",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, labels in dataloaders['train']:\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b678061",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_MVN = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f737204e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_MVN.base_sample_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b557ae44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 384, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood(pred_MVN).probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef293e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean_prob = likelihood(pred_MVN).probs.mean(0)\n",
    "pred = pred_mean_prob.max(dim=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03aec1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(pred_MVN, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fccd4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(55.0969, device='cuda:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31c2b3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6005, 0.3995],\n",
       "        [0.5145, 0.4855],\n",
       "        [0.4735, 0.5265],\n",
       "        [0.5037, 0.4963],\n",
       "        [0.5575, 0.4425],\n",
       "        [0.4396, 0.5604],\n",
       "        [0.4145, 0.5855],\n",
       "        [0.4609, 0.5391],\n",
       "        [0.4923, 0.5077],\n",
       "        [0.5740, 0.4260],\n",
       "        [0.5006, 0.4994],\n",
       "        [0.3756, 0.6244],\n",
       "        [0.4784, 0.5216],\n",
       "        [0.4453, 0.5547],\n",
       "        [0.4729, 0.5271],\n",
       "        [0.2812, 0.7188],\n",
       "        [0.5067, 0.4933],\n",
       "        [0.5373, 0.4627],\n",
       "        [0.4764, 0.5236],\n",
       "        [0.6365, 0.3635],\n",
       "        [0.4937, 0.5063],\n",
       "        [0.4666, 0.5334],\n",
       "        [0.5238, 0.4762],\n",
       "        [0.4606, 0.5394],\n",
       "        [0.5955, 0.4045],\n",
       "        [0.5134, 0.4866],\n",
       "        [0.4719, 0.5281],\n",
       "        [0.5662, 0.4338],\n",
       "        [0.5675, 0.4325],\n",
       "        [0.5378, 0.4622],\n",
       "        [0.4792, 0.5208],\n",
       "        [0.4352, 0.5648],\n",
       "        [0.5509, 0.4491],\n",
       "        [0.6218, 0.3782],\n",
       "        [0.6447, 0.3553],\n",
       "        [0.4988, 0.5012],\n",
       "        [0.6204, 0.3796],\n",
       "        [0.5447, 0.4553],\n",
       "        [0.5146, 0.4854],\n",
       "        [0.5193, 0.4807],\n",
       "        [0.5358, 0.4642],\n",
       "        [0.6953, 0.3047],\n",
       "        [0.4336, 0.5664],\n",
       "        [0.4247, 0.5753],\n",
       "        [0.5217, 0.4783],\n",
       "        [0.4905, 0.5095],\n",
       "        [0.5117, 0.4883],\n",
       "        [0.4899, 0.5101],\n",
       "        [0.5516, 0.4484],\n",
       "        [0.4628, 0.5372],\n",
       "        [0.5092, 0.4908],\n",
       "        [0.5671, 0.4329],\n",
       "        [0.5080, 0.4920],\n",
       "        [0.6215, 0.3785],\n",
       "        [0.4278, 0.5722],\n",
       "        [0.4538, 0.5462],\n",
       "        [0.5489, 0.4511],\n",
       "        [0.4229, 0.5771],\n",
       "        [0.3591, 0.6409],\n",
       "        [0.5037, 0.4963],\n",
       "        [0.5952, 0.4048],\n",
       "        [0.5486, 0.4514],\n",
       "        [0.4737, 0.5263],\n",
       "        [0.6725, 0.3275],\n",
       "        [0.5274, 0.4726],\n",
       "        [0.4948, 0.5052],\n",
       "        [0.5808, 0.4192],\n",
       "        [0.5342, 0.4658],\n",
       "        [0.3692, 0.6308],\n",
       "        [0.4580, 0.5420],\n",
       "        [0.6227, 0.3773],\n",
       "        [0.3849, 0.6151],\n",
       "        [0.4567, 0.5433],\n",
       "        [0.5130, 0.4870],\n",
       "        [0.3494, 0.6506],\n",
       "        [0.3620, 0.6380],\n",
       "        [0.4882, 0.5118],\n",
       "        [0.4542, 0.5458],\n",
       "        [0.3173, 0.6827],\n",
       "        [0.5209, 0.4791],\n",
       "        [0.4755, 0.5245],\n",
       "        [0.4458, 0.5542],\n",
       "        [0.5766, 0.4234],\n",
       "        [0.5071, 0.4929],\n",
       "        [0.5007, 0.4993],\n",
       "        [0.4763, 0.5237],\n",
       "        [0.3935, 0.6065],\n",
       "        [0.5582, 0.4418],\n",
       "        [0.4552, 0.5448],\n",
       "        [0.5019, 0.4981],\n",
       "        [0.7120, 0.2880],\n",
       "        [0.3871, 0.6129],\n",
       "        [0.5051, 0.4949],\n",
       "        [0.4893, 0.5107],\n",
       "        [0.5182, 0.4818],\n",
       "        [0.5567, 0.4433],\n",
       "        [0.3492, 0.6508],\n",
       "        [0.5844, 0.4156],\n",
       "        [0.4840, 0.5160],\n",
       "        [0.5158, 0.4842],\n",
       "        [0.4777, 0.5223],\n",
       "        [0.4997, 0.5003],\n",
       "        [0.4392, 0.5608],\n",
       "        [0.4386, 0.5614],\n",
       "        [0.4378, 0.5622],\n",
       "        [0.4582, 0.5418],\n",
       "        [0.4414, 0.5586],\n",
       "        [0.3752, 0.6248],\n",
       "        [0.4257, 0.5743],\n",
       "        [0.5466, 0.4534],\n",
       "        [0.4833, 0.5167],\n",
       "        [0.4332, 0.5668],\n",
       "        [0.4007, 0.5993],\n",
       "        [0.5706, 0.4294],\n",
       "        [0.5092, 0.4908],\n",
       "        [0.4565, 0.5435],\n",
       "        [0.4646, 0.5354],\n",
       "        [0.4716, 0.5284],\n",
       "        [0.3880, 0.6120],\n",
       "        [0.5197, 0.4803],\n",
       "        [0.4991, 0.5009],\n",
       "        [0.4558, 0.5442],\n",
       "        [0.5156, 0.4844],\n",
       "        [0.6076, 0.3924],\n",
       "        [0.5214, 0.4786],\n",
       "        [0.4094, 0.5906],\n",
       "        [0.4257, 0.5743],\n",
       "        [0.5204, 0.4796]], device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mean_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72874af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ee484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583d274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f698fb67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed8cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = feature_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d70bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9a607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_pred.reshape(-1,1), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1817236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VisiumClassificationDataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.transforms??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc9c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c699d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy().transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf169f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x[2,:,:].numpy().reshape(-1,1), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x.numpy().reshape(-1,1), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a1c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = x.numpy().transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ed7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd2417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lit_torch_gp",
   "language": "python",
   "name": "lit_torch_gp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
